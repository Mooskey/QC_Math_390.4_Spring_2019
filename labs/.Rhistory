lambda1 * v1
B %*% v2
lambda2 * v2
B %*% v2 == lambda2 * v2 #why not?
#diagonolization
V %*% diag(lambdas) %*% solve(V)
y = MASS::Boston$medv
X = as.matrix(cbind(1, MASS::Boston[, 1: 13]))
Xt = t(X)
XtXinv = solve(Xt %*% X)
b = XtXinv %*% t(X) %*% y
b
H = X %*% XtXinv %*% t(X)
yhat = X %*% b
yhat = H %*% y
e = y - yhat
head(e)
SSE = t(e) %*% e
MSE = 1 / (ncol(X)) * SSE
RMSE = sqrt(MSE)
SSE
MSE
RMSE
s_sq_y = var(y)
s_sq_e = var(e)
Rsq = (s_sq_y - s_sq_e) / s_sq_y
Rsq
n = length(e)
SST = (n - 1) * s_sq_y
Rsq = 1 - SSE / SST
Rsq
t(e) %*% yhat
sum(y)^2 - sum(yhat)^2 - sum(e)^2
pacman::p_load(testthat)
expect_equal(H, t(H), tolerance = 1e-2)
expect_equal(H %*% H, H, tolerance = 1e-2)
pacman::p_load(Matrix)
rankMatrix(H)
eigenvals = as.numeric(round(eigen(H)$values, 4))
eigenvals
sum(eigenvals)
eigenvals = as.numeric(round(eigen(diag(nrow(H)) - H)$values, 4))
eigenvals
sum(eigenvals)
n = 20
x1 = rnorm(n)
x2 = x1
x2[n] = x1 + 0.0001
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.2)
y = X %*% bbeta + epsilon
X
X %*% bbeta
epsilon
X %*% bbeta + epsilon
epsilon = rnorm(n, mean = 0, sd = 0.2)
y = X %*% bbeta + epsilon
n = 20
x1 = rnorm(n)
x2 = x1
x2[n] = x1 + 0.0001
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.2)
y = X %*% bbeta + epsilon
X = cbind(1, x1, x2)
n = 20
x1 = rnorm(n)
x2 = x1
x2[n] = x1 + 0.0001
X = cbind(1, x1, x2)
n = 20
x1 = rnorm(n)
x2 = x1
x2[n] = x1[n] + 0.0001
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.2)
y = X %*% bbeta + epsilon
mod = lm(y ~ X)
coef(mod)
summary(mod)$r.squared
b = solve(t(X) %*% X) %*% t(X) %*% y
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2 = x1 + rnorm(n)
X = cbind(1, x1, x2)
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2 = x1 + rnorm(n)
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2 = x1 + rnorm(n)
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2[n] = x1[n] + rnorm(n, 0, 0.1)
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.1)
y = X %*% bbeta + epsilon
x2[n] = x + rnorm(n, 0, 0.1)
x2[n] = x1 + rnorm(n, 0, 0.1)
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.1)
y = X %*% bbeta + epsilon
x2 = x1 + rnorm(n, 0, 0.1)
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.1)
y = X %*% bbeta + epsilon
x2 = x1 + rnorm(n)
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2 = rnorm(n)
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
t(x1) %*% x2
n = 20
x1 = rnorm(n)
x2 = x1
x2[n] = x1[n] + 0.0001
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.1)
y = X %*% bbeta + epsilon
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2)))
x2 = x1 + rnorm(n, 0, 0.1)
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.1)
y = X %*% bbeta + epsilon
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2)))
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
n = 20
x1 = rnorm(n)
x2 = x1
x2[n] = x1[n] + 0.0001
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.1)
y = X %*% bbeta + epsilon
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
x2 = x1 + rnorm(n, 0, 0.1)
X = cbind(1, x1, x2)
bbeta = c(2, -3, 5)
epsilon = rnorm(n, mean = 0, sd = 0.1)
y = X %*% bbeta + epsilon
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
x2 = rnorm(n)
X = cbind(1, x1, x2)
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2 = x1 + rnorm(n, 0, 0.1)
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2 = x1 + rnorm(n, 0, 0.01)
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
x2 = x1 + rnorm(n, 0, 0.05)
t(x1) %*% x2
acos(t(x1) %*% x2 / sqrt(sum(x1^2) * sum(x2^2))) * 180 / pi
X = cbind(1, x1, x2)
y = X %*% bbeta + epsilon
XtXinvXt = solve(t(X) %*% X) %*% t(X)
b = XtXinvXt %*% y
H = X %*% XtXinvXt
e = (diag(n) - H) %*% y
b
1 - sum(e^2) / sum((y - mean(y))^2)
X = rnorm(n)
n = 100
X = rnorm(n)
x = x - mean(x)
n = 100
x = rnorm(n)
x = x - mean(x)
y = rnorm(n)
y = y - mean(y)
x %*% y
x %*% y
theta = acos(x %*% y / sqrt(sum(x^2) * sum(y^2)))
theta * 180 / pi
cor(x, y)
bbeta = c(2, 3, -4, 5)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[1, ] = coef(lm(y ~ X))
all_betas
coef(lm(y ~ X))
all_betas[1, ] = coef(lm(y ~ 0 + X))
all_betas = matrix(NA, n, n)
all_betas[1, ] = coef(lm(y ~ 0 + X))
all_betas[1, ]
all_betas = matrix(NA, n, n)
all_betas[1, 1 : 4] = coef(lm(y ~ 0 + X))
all_betas[1,]
all_betas = matrix(NA, n, n)
all_betas[1, 1 : 4] = coef(lm(y ~ 0 + X))
for (j in 5 : n){
X = cbind(X, rnorm(n))
all_betas[1, 1 : j] = coef(lm(y ~ 0 + X))
}
all_betas
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
coef(lm(y ~ 0 + X))
bbeta = c(2, 3, -4, 5)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
for (j in 5 : n){
X = cbind(X, rnorm(n))
all_betas[j, 1 : j] = coef(lm(y ~ 0 + X))
}
all_betas
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
for (j in 5 : n){
X = cbind(X, rnorm(n))
all_betas[j, 1 : j] = coef(lm(y ~ 0 + X))
}
j
all_betas
all_betas[4 : n, 1 : 4]
bbeta = c(1, 2, 3, 4)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
for (j in 5 : n){
X = cbind(X, rnorm(n))
all_betas[j, 1 : j] = coef(lm(y ~ 0 + X))
}
all_betas[4 : n, 1 : 4]
sum((all_betas[4 : n, 1 : 4] - bbeta)^2)
(all_betas[4 : n, 1 : 4] - bbeta)^2
(all_betas[n, 1 : 4] - bbeta)^2
rowSums((all_betas[4 : n, 1 : 4] - bbeta)^2)
all_betas[90, 1 : 4]
matrix(rep(bbeta, n), nrow = n - 4)
matrix(rep(bbeta, n), nrow = n - 4, byrow = TRUE)
matrix(rep(bbeta, n), nrow = n - 3, byrow = TRUE)
matrix(rep(bbeta, n), nrow = n, byrow = TRUE)
rowSums((all_betas[, 1 : 4] - matrix(rep(bbeta, n), nrow = n, byrow = TRUE))^2)
error_by_p = rowSums((all_betas[, 1 : 4] - matrix(rep(bbeta, n), nrow = n, byrow = TRUE))^2)
plot(1 : n, error_by_p)
#look at out of sample error
oos_rmse_by_p = array(NA, n)
for (j in 4 : n){
y_hat_star = X_star %*% all_betas[j, 1 : 4]
oos_rmse_by_p[j] = sqrt(sum((y_star - y_hat_star)^2))
}
plot(1 : n, oos_rmse_by_p)
y = rnorm(n)
Rsqs = array(NA, n)
#we know that Rsq = 0 for the null model
Rsqs[1] = 0
#create a matrix with the correct number of rows but no columns
X = matrix(NA, nrow = n, ncol = 0)
#for every new p, tack on a new random continuos predictor:
for (p_plus_one in 2 : n){
X = cbind(X, rnorm(n))
Rsqs[p_plus_one] = summary(lm(y ~ X))$r.squared
}
pacman::p_load(ggplot2)
base = ggplot(data.frame(p_plus_one = 1 : n, Rsq = Rsqs))
base + geom_line(aes(x = p_plus_one, y = Rsq))
pacman::p_load(latex2exp)
base + geom_line(aes(x = p_plus_one, y = c(0, diff(Rsq)))) + xlab("p + 1") + ylab(TeX("$\\Delta R^2$"))
all(diff(Rsqs) > 0)
bbeta = c(1, 2, 3, 4)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
for (j in 5 : n){
X = cbind(X, rnorm(n))
all_betas[j, 1 : j] = coef(lm(y ~ 0 + X))
}
all_betas[4 : n, 1 : 4]
b_error_by_p = rowSums((all_betas[, 1 : 4] - matrix(rep(bbeta, n), nrow = n, byrow = TRUE))^2)
plot(1 : n, b_error_by_p)
#look at out of sample error
oos_rmse_by_p = array(NA, n)
for (j in 4 : n){
y_hat_star = X_star %*% all_betas[j, 1 : 4]
oos_rmse_by_p[j] = sqrt(sum((y_star - y_hat_star)^2))
}
plot(1 : n, oos_rmse_by_p)
bbeta = c(1, 2, 3, 4)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
for (j in 5 : n){
X = cbind(X, rnorm(n))
lm_mod = lm(y ~ 0 + X)
all_betas[j, 1 : j] = coef(lm_mod)
y_hat = X[, 1 : 4] %*% all_betas[, 1 : 4]
}
X[, 1 : 4]
all_betas[, 1 : 4]
y_hat = X[, 1 : 4] %*% all_betas[j, 1 : 4]
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
bbeta = c(1, 2, 3, 4)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
in_sample_rmse_by_p = array(NA, n)
for (j in 5 : n){
X = cbind(X, rnorm(n))
lm_mod = lm(y ~ 0 + X)
all_betas[j, 1 : j] = coef(lm_mod)
y_hat = X[, 1 : 4] %*% all_betas[j, 1 : 4]
in_sample_rmse_by_p = sqrt(sum((y - y_hat)^2))
}
plot(1 : n, oos_rmse_by_p)
plot(1 : n, in_sample_rmse_by_p)
bbeta = c(1, 2, 3, 4)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
in_sample_rmse_by_p = array(NA, n)
for (j in 5 : n){
X = cbind(X, rnorm(n))
lm_mod = lm(y ~ 0 + X)
all_betas[j, 1 : j] = coef(lm_mod)
y_hat = X[, 1 : 4] %*% all_betas[j, 1 : 4]
in_sample_rmse_by_p[j] = sqrt(sum((y - y_hat)^2))
}
plot(1 : n, in_sample_rmse_by_p)
oos_rmse_by_p = array(NA, n)
for (j in 5 : n){
X_star = cbind(X_star, rnorm(n))
y_hat_star = X_star %*% all_betas[j, 1 : j]
oos_rmse_by_p[j] = sqrt(sum((y_star - y_hat_star)^2))
}
plot(1 : n, oos_rmse_by_p)
bbeta = c(1, 2, 3, 4)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
in_sample_rmse_by_p = array(NA, n)
for (j in 5 : n){
X = cbind(X, rnorm(n))
lm_mod = lm(y ~ 0 + X)
all_betas[j, 1 : j] = coef(lm_mod)
y_hat = X[, 1 : 4] %*% all_betas[j, 1 : 4]
in_sample_rmse_by_p[j] = sqrt(sum((y - y_hat)^2))
}
bbeta = c(1, 2, 3, 4)
#build training data
n = 100
X = cbind(1, rnorm(n), rnorm(n), rnorm(n))
y = X %*% bbeta + rnorm(n, 0, 0.3)
#build test data
n_star = 100
X_star = cbind(1, rnorm(n), rnorm(n), rnorm(n_star))
y_star = X_star %*% bbeta + rnorm(n, 0, 0.3)
all_betas = matrix(NA, n, n)
all_betas[4, 1 : 4] = coef(lm(y ~ 0 + X))
in_sample_rmse_by_p = array(NA, n)
for (j in 5 : n){
X = cbind(X, rnorm(n))
lm_mod = lm(y ~ 0 + X)
all_betas[j, 1 : j] = coef(lm_mod)
y_hat = X %*% all_betas[j, 1 : j]
in_sample_rmse_by_p[j] = sqrt(sum((y - y_hat)^2))
}
plot(1 : n, in_sample_rmse_by_p)
all_betas[4 : n, 1 : 4]
b_error_by_p = rowSums((all_betas[, 1 : 4] - matrix(rep(bbeta, n), nrow = n, byrow = TRUE))^2)
plot(1 : n, b_error_by_p)
oos_rmse_by_p = array(NA, n)
for (j in 4 : n){
y_hat_star = X_star %*% all_betas[j, 1 : 4]
oos_rmse_by_p[j] = sqrt(sum((y_star - y_hat_star)^2))
}
plot(1 : n, oos_rmse_by_p)
#look at out of sample error in the case of the random features too
oos_rmse_by_p = array(NA, n)
for (j in 5 : n){
X_star = cbind(X_star, rnorm(n))
y_hat_star = X_star %*% all_betas[j, 1 : j]
oos_rmse_by_p[j] = sqrt(sum((y_star - y_hat_star)^2))
}
plot(1 : n, oos_rmse_by_p)
